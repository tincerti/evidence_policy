\documentclass[12pt,final,fleqn]{article}

% basic packages
\usepackage[margin=1in] { geometry }
\usepackage{amssymb,amsmath, bm}
\usepackage{verbatim}
\usepackage[latin1]{inputenc}
%\usepackage[OT1]{fontenc}
\usepackage{setspace}
\usepackage{enumitem}
\usepackage{url}
\usepackage[font={bf}]{caption}
\usepackage{float}
%\usepackage{pgfplots}
%\usepackage[font={bf}]{caption}
\usepackage{setspace}
\usepackage{latexsym}
%\usepackage{euscript}
\usepackage{graphicx}
\usepackage{marvosym}
\usepackage{amsmath} 
\usepackage{authblk}
\usepackage{xcolor}
%\usepackage[varg]{txfonts}  Older version of ``g'' in math.

% bibliography packages
\usepackage[natbibapa]{apacite}
\bibliographystyle{apacite}
\bibpunct{(}{)}{;}{a}{}{,}
\renewcommand{\bibname}{References}

% hyperref options
\usepackage{color}
\usepackage{hyperref}
\usepackage{xcolor}
\hypersetup{
    colorlinks,
    linkcolor={blue!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}
\newcommand*{\Appendixautorefname}{Appendix}
\renewcommand*{\sectionautorefname}{Section}
\renewcommand*{\subsectionautorefname}{Section}
\newcommand{\aref}[1]{\hyperref[#1]{Appendix~\ref{#1}}}

% packages for tables
\usepackage{longtable}
\usepackage{booktabs, threeparttable}
\usepackage{threeparttablex}
%\usepackage{tabularx}
% dcolumn package
\usepackage{dcolumn}
\newcolumntype{.}{D{.}{.}{-1}}
\newcolumntype{d}[1]{D{.}{.}{#1}}
\captionsetup{belowskip=10pt,aboveskip=-5pt}
\usepackage{multirow}
% rotating package
\usepackage[figuresright]{rotating}
\usepackage{pdflscape}
\usepackage{subcaption}

% packages for figures
\usepackage{grffile}
\usepackage{afterpage}
\usepackage{float}
\usepackage[section]{placeins}


% theorem package
\usepackage{theorem}
\theoremstyle{plain}
\theoremheaderfont{\scshape}
\newtheorem{hyp}{Hypothesis}
\newtheorem{theorem}{Theorem}
\newtheorem{algorithm}{Algorithm}
\newtheorem{assumption}{Assumption}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
\newtheorem{remark}{Remark}
\newcommand{\qed}{\hfill \ensuremath{\Box}}
\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\argmin}{arg\min}
\DeclareMathOperator{\argmax}{arg\max}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\providecommand{\norm}[1]{\lVert#1\rVert}
\renewcommand\r{\right}
\renewcommand\l{\left}
\newcommand\E{\mathbb{E}}
\newcommand\dist{\buildrel\rm d\over\sim}
\newcommand\iid{\stackrel{\rm i.i.d.}{\sim}}
\newcommand\ind{\stackrel{\rm indep.}{\sim}}
\newcommand\cov{{\rm Cov}}
\newcommand\var{{\rm Var}}
\newcommand\SD{{\rm SD}}
\newcommand\bone{\mathbf{1}}
\newcommand\bzero{\mathbf{0}}

% dotted lines in tables
%\usepackage{arydshln}

\usepackage{pdflscape}

% spacing between sections and subsections
\usepackage[compact]{titlesec}

% times new roman
%\usepackage{times}

% appendix settings
\usepackage[toc,page,header]{appendix}
\renewcommand{\appendixpagename}{\centering Appendices}
\usepackage{chngcntr}
\usepackage{etoolbox}
\usepackage{lipsum}


% file paths and definitions
\makeatletter
\newcommand*\ExpandableInput[1]{\@@input#1 }
\makeatother

\setlength{\mathindent}{1cm}
\allowdisplaybreaks[4]
\doublespacing
%\special{pdf: pagesize width 8.5truein height 11.0truein}

\titleformat{\subsection}
  {\itshape\large}{\thesubsection}{1em}{}

\setcounter{tocdepth}{1}

%--------------------------------------------------------------------------------------
% BEGIN DOCUMENT
%--------------------------------------------------------------------------------------

\begin{document}
\singlespace
\title{\textbf{Policy-makers and evidence: double standards? A field experiment \\
(Pre-Analysis Plan)}\vspace{-1ex}\thanks{}}
% Thanks
\author{Angele Delevoye\thanks{angele.delevoye@yale.edu}\vspace{-1ex}}
\author{Trevor Incerti\thanks{trevor.incerti@yale.edu}\vspace{-1ex}}
\affil{\textit{Yale University}\vspace{-2.5ex}}
\date{\today}
\maketitle

\begin{abstract}
\noindent
The bipartisan Foundations for Evidence-Based Policymaking Act of 2018 stresses the need for evidence-based policy-making. We propose a field experiment that tests whether legislators are in actuality more receptive to higher standards of evidence in research when receiving policy-information. A related question is if legislators possess sufficient knowledge of evidence standards to be able to differentiate between varying standards of research quality. This pre-analysis plan proposes a field-experimental research design dedicated to answering these questions, and pre-registers the procedures that will be used to conduct this analysis.
\end{abstract}

\pagebreak

\doublespace

\begin{center}
%[PREMIMINARY DRAFT: INCOMPLETE]
\end{center}

\section{Introduction} \label{sec:Introduction}

The need for more evidence-based policy-making is the object of a rare bipartisan agreement. Congress passed the Foundations for Evidence-Based Policymaking Act in 2018 - legislation sponsored by then-House Speaker Paul Ryan (R-WI) and Senator Patty Murray (D-WA). Only 17 representatives voted against, and it passed the Senate by unanimous consent. Policy-makers' intentions are clear, but do their behaviors and knowledge align with those intentions? Are policy-makers really more receptive to higher standards of evidence when evaluating policy-information? Moreover, even if policymakers want to adopt policies based on high-quality evidence, do they have sufficient knowledge of evidence standards to be able to differentiate between research of varying quality? 

We propose a field experiment to test: (1) whether policymakers give more credence to high quality research, and (2) if policymakers can recognize differences in research quality. Our research design would entail contacting policy-makers with information regarding research on a potential educational policy while randomizing the kind of research design from which study derives its evidence - from a simple regression to a well-conducted RCT. We would also randomize whether we provide the policy-maker with information about varying standards of evidence within academic research (e.g. informing them that an RCT is considered the gold standard in causal inference and policy evaluation studies). 

Our pre-analysis first presents the theory and existing literature we hope to advance. In particular, we hope to build on existing experimental studies that have contacted American policy-makers. Next, we present the details of our proposed experimental design: treatment (choice of policy and evidence standard), logistics (partnership with a 3rd party organization), outcome measures, and ethical considerations. These details on the design are still preliminary, and several open questions remain. We conclude with a power analysis for the proposed experiment.


\section{Theory} \label{sec:Theory}
\subsection{Evidence in policymaking}  \label{sec: evidence}

A growing literature examines if, when, and how evidence and expertise is used in policy-making. The conventional wisdom from the this literature in the US Congressional context has long been that evidence and information do not matter. Legislators are focused on reelection \citep{mayhew1974congress}, power within Congress \citep{fenno1973congressmen}, and responding to pressures from local constituents \citep{fenno2002home}. \citet{schick1976supply} concluded in 1976 that ``Congress is not a natural habit for policy analysis," and \citet{lindblom2018science} states that the best Congress can do is "muddle through" given institutional constraints and lack of time and resources. 

Recently, however, scholars have called for a more nuanced understanding of the use of evidence in policy-making. [\citet{patashnik2016can}, despite well-identified methodological challenges \citep{mandell1984approaches}.] Case studies have suggested that evidence is used in policy-making, but we need a better understanding of how (much), when and why. Scholars have also examined the supply of scientific evidence, and have looked how scientists can maximize the use of scientific evidence. \citet{cairney2016politics} lays out two types of shortcuts used by legislators, rational decision-making and irrational decision-making drawing on emotions, beliefs and habits. He argues that scientists have mostly focused on the former, and that they should do a better job at accompanying evidence with simple stories to exploit the emotional or ideological biases of policymakers. We hope to test and measure legislators' ability to respond to the first, rational type of stimulus. 

Depending on what and who the source of the information ends up being in the experiment, we could also look at literatures on messenger effects (does the source of information matter?), relations between diverse groups and policy-makers, etc. The initial goal is to conduct this experiment with the U.S. Congress, but we might end up conducting it at the State or more local levels (cf. below). In that case, literatures on state and local politics would come into play. Finally, this project might address broader, more theoretical questions on the functioning of our current democracies, and the potential gaps between reality and the ideals of deliberative democracies. We are also hoping that this project will contribute to ongoing philosophy of science discussions. What is the value of our different methods outside of the research community bubble, how are they perceived and understood by different targets (policy-makers for this specific experiment, but a similar experiment could later be conducted with citizens)? 

\subsection{Legislator contact experiments}  \label{sec: contact experiments}

Randomized contact of legislators in American politics research remains relatively rare. \autoref{tab:audit_experiments} below summarizes previous studies. Our design most closely resembles a mix of the experiments conducted by \citet{butler2011politicians} and \citet{kalla2016campaign}. Our factorial design will come close to \citet{butler2011politicians}'s 2x3 design (and may use their contact list for state legislatures). We also plan to emulate \citet{kalla2016campaign}'s use of a third party organization to contact legislators, as well as their more nuanced outcome measure: both rate of response to emails and the seniority of the person who has agreed to meet with the organization. The use of roll call votes as in \citet{bergan2009does} is likely only possible for an experiment that targets one bill in one Chamber. Roll call votes is not a realistic outcome measure in our case: even if we were to reach out with policy information on a specific bill, too much would happen between us reaching out and the MC eventual vote for us to be able to isolate the effect of us reaching out. 




\begin{sidewaystable}[]
\caption{Audit experiments conducted with U.S. policy-makers}
\label{tab:audit_experiments} 
\bigbreak
\tiny
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
Reference      
& Federal/State                                                                                                                        & Arms 
& Treatment                                                                                                           
& Design                                                                                                                                                        & Outcome 
& 3rd party?                                                                                                                                                                                                                                                  \\ \hline
 \citet{bergan2009does}        
& \begin{tabular}[c]{@{}l@{}}State \\ (New Hampshire) \end{tabular}                                                  & 1
& \begin{tabular}[c]{@{}l@{}} Contacted \\ by activists \end{tabular}                                           & \begin{tabular}[c]{@{}l@{}}Matched pairs \\ (multimembers districts)\\ Randomization within party\\ and district stratas\end{tabular}                         
& Roll Call votes                                                                                            
& \begin{tabular}[c]{@{}l@{}}Yes: coalition of \\ public health-related groups\\  organizing a grassroots email \\ lobbying campaign by activists\end{tabular}                                                                                              
  \\ \hline
 \citet{butler2011politicians}       & \begin{tabular}[c]{@{}l@{}}4,859 state legislators\\ (44 states)\end{tabular}                                                        & 2x3          & \begin{tabular}[c]{@{}l@{}}Black or \\ white name and\\ party (D/R/blank)\\ of email sender\end{tabular}            & \begin{tabular}[c]{@{}l@{}}Block randomization\\ by state, chamber, \\ party, and whether\\ legislator is up for \\ reelection\end{tabular}                   & \begin{tabular}[c]{@{}l@{}}Rate of response\\ to emails\end{tabular}                                       & No                                                                                                                                                                                                                                                          \\ \hline
 \citet{kalla2016campaign}     & \begin{tabular}[c]{@{}l@{}}US Congress \\ 191 offices that had \\ not yet sponsored bill \end{tabular} & 1            & \begin{tabular}[c]{@{}l@{}}Reveal in email that\\ prospective attendees had\\ contributed to campaigns\end{tabular} & \begin{tabular}[c]{@{}l@{}}Blocks of 3 offices: closest\\ similarity on multiple \\ covariates\\ 1 treated, 2 control in each\\ of the 64 blocks\end{tabular} & \begin{tabular}[c]{@{}l@{}}Rate of response\\ to emails and\\ seniority of proposed\\ meeting\end{tabular} & \begin{tabular}[c]{@{}l@{}}Yes: liberal political organization \\ trying to set meetings between offices\\ and constituents who had previously \\ given to campaigns. \\ Goal of the meetings: rally support for \\ a bill banning a chemical.\end{tabular} 
 \\ \hline
  \citet{doberstein2017whom}     & \begin{tabular}[c]{@{}l@{}}1,108 \\ Canadian bureaucrats\end{tabular} & 2x2           & \begin{tabular}[c]{@{}l@{}}Source of the\\ policy information \\(academic, think tanks, \\ research-based \\advocacy groups) \end{tabular} & \begin{tabular}[c]{@{}l@{}}Sources in \\treatment groups \\ were falsified \\  Pre treatment survey\\ for covariates \end{tabular} & \begin{tabular}[c]{@{}l@{}} Credibility assessment of \\each of 5 research articles \\ Based on summaries \\ And ranking of the 5 articles \end{tabular} & \begin{tabular}[c]{@{}l@{}}No.\end{tabular} 
   \\ \hline
  \citet{zelizer2018responsive}     & \begin{tabular}[c]{@{}l@{}}18 bills \\ 76 state legislators \end{tabular} & 1          & \begin{tabular}[c]{@{}l@{}}Assigned to in-person\\ briefings by a \\ committee staffer \end{tabular} & \begin{tabular}[c]{@{}l@{}}Treatment assigned \\ at legislator-bill \\ dyad level \\ block RA \end{tabular} & \begin{tabular}[c]{@{}l@{}} Cosponsorship of bills \\ Roll-call votes \end{tabular} & \begin{tabular}[c]{@{}l@{}}No.\end{tabular} 
     \\ \hline
  \citet{butler2011can}     & \begin{tabular}[c]{@{}l@{}}New Mexico State House \\ 70 legislators \end{tabular} & 1          & \begin{tabular}[c]{@{}l@{}}Received district-specific \\survey results on \\constituents' opinions \\on a bill \end{tabular} & \begin{tabular}[c]{@{}l@{}}35 matched pairs \end{tabular} & \begin{tabular}[c]{@{}l@{}} Cosponsorship of bills \\ Roll-call votes \end{tabular} & \begin{tabular}[c]{@{}l@{}}Use of University Logo \\ And email from \\ own researchers' address\end{tabular} 
       \\ \hline
  \citet{butler2012field}     & \begin{tabular}[c]{@{}l@{}}489 legislatives offices \\ 23 states \\ 1,036 letters \end{tabular} & 2x4        & \begin{tabular}[c]{@{}l@{}}Received letter \\ ethnicity of sender varied \\ 2 ethnicities \\  type of letter varied \\ 4 types (policy vs service, \\ level of knowledge) \end{tabular} & \begin{tabular}[c]{@{}l@{}}35 matched pairs \end{tabular} & \begin{tabular}[c]{@{}l@{}} Rate of response \\ Roll-call votes \end{tabular} & \begin{tabular}[c]{@{}l@{}}Yes: actual individuals \\ 200 students at BYU \\ Opened post office boxes \\ in their hometown \end{tabular} \\
\hline
\end{tabular}
\end{sidewaystable}


\section{Experimental design} \label{sec:Design}

\subsection{Treatment groups and randomization} \label{sec:Treatment}

Policy-makers will be contacted and provided with information on findings from a policy study. This will take the form of a 2x2 factorial design with two treatments: (i) the evidence standard used in the study (low vs high) and (ii) whether we provide policy-makers with information explaining the evidence standards. \autoref{tab: arms} synthesizes our treatment arms. Additional details regarding the types of evidence standards and policies included in each arm are described in \nameref{sec:Evidence} below. 

Given the small sample size inherent in any study using a sample of legislators, we will conduct block random assignment based upon a vector of pre-treatment covariates in order to increase the precision of our treatment effect estimates. Examples of pre-treatment covariates that can be used to create the blocks would be party, chamber, education level of the legislator (if data is available), closeness of the district, state, etc. In other words, legislators will be divided into blocks based on these pre-treatment covariates, then will be randomly assigned to a treatment condition within each block. Which treatment arm (i.e. form of contact) a policy-maker receives will be randomized using complete random assignment, and will in practice be conducted using the ``complete\_ra'' function in the R package \textit{randomizr} (part of the \textit{DeclareDesign} suite).

\begin{table}[H]
\centering
\caption{Treatment arms: 2x2 factorial design}
\label{tab: arms} 
\bigbreak
\begin{tabular}{|l|l|l|l|l|}
\hline
&Lower Tier & Higher Tier           \\ \hline
No information & Control    &  High and no info           \\ \hline
Information    & Low and info       &  High and info              \\ \hline
\end{tabular}
\end{table}

\subsection{Evidence standards} \label{sec:Evidence}

We rely on evidence standards and descriptions already adopted in some laws (Elementary and Secondary Education Act - ESEA 65, No Child Left Behind - NCLB 01, Every Student Succeeds Act - ESSA 15) and used by the Department of Education (DoE) and Department of Labor (DoL). The DoL defines three tiers of evidence: high causal evidence (primarily RCTs), moderate causal evidence (strong non-experimental designs or RCTs with high attrition) or low causal evidence studies. The DOL defines the low causal studies as studies that do not meet criteria for a high or moderate evidence rating. Those studies, according to the DoL, show little evidence that the effects estimated in the study are attributable to the intervention being examined, and other factors are likely to have contributed to the results. They should be interpreted with caution. The DoE has adopted similar standards (see \autoref{sec: DoE}). 

We use these standards because they are ostensibly used in actual policy-making decisions. These definitions already exist, are specified in law and implementation texts, and have been referenced in previous projects and studies (see below). For simplicity sake, statistical power reasons as well as substantive interest, we will focus on the studies from the higher tier of evidence and those from the lowest tier. This will keep our factorial design to a manageable 2x2 design. One downside of this approach is that it may require us to restrict ourselves to quantitative studies.\footnote{We have not yet looked at the databased and associated studies. We doubt it, but it is possible that qualitative studies are already incorporated into the databases and one of the 3 evidence standards} We will need to think about whether we want to add qualitative studies as an additional category. We will also need to check whether qualitative studies are used in the DoE and DoL databases, and if yes, under which tier of evidence. 

\subsection{Choice of policy} \label{sec: Policy}

The policy and specific findings we will report on are yet to be determined. Ideally, we would use similar findings coming from 3 or 4 studies belonging to different tiers of evidence. The DoE and DoL each have comprehensive databases of most studies conducted in their respective policy areas, their findings and the evidence tier to which they belong. We can leverage these existing databases (What Works Clearing House for the DoE, CLEAR for the DoL) in order to find studies we can use in our experiment. 

For ethical reasons we will need to locate studies that reach similar results using different methods (ethics are considered in more detail in the \nameref{sec:Ethics} section below). More specifically, the results of the studies will need to be similar enough to use the same one-sentence summaries in our messages without resorting to deception. Depending on the studies that we find, we might need to be more or less specific in the formulation of the results in our email (it could be anything from a very broad result such as 'small classes are better' to more specific results such as 'adding curriculum x to classes y raises z'). Ideally, the results would also be surprising or new, in order to both maximize the level of new information we are providing, as well as to raise the incentives of meeting with an organization regarding the results. For example, providing policymakers with information regarding an educational policy that has already been adopted would be ignored for reasons unrelated to the content of the randomized treatments. 

\subsection{Outcomes} \label{sec: Outcomes}
What outcomes we would measure and how is still an open question. The more realistic solution would be to measure response rates to our email. If we are more ambitious and partner with a 3rd party organization, we could ask to set meetings and use the seniority of whoever we get a meeting with as another measure of the importance given to our approach. The model for this would be \citet{kalla2016campaign}. If we actually set meetings (through a third-party organization), more qualitative observations of policy-makers? understanding of and responsiveness to evidence standards could be gathered. 

\subsection{Partnership with 3rd party organization} \label{sec: Partnership}

The source of the email will be important, and has yet to be determined. In order to maximize the realism and reach of the experiment, we will probably need to partner with a third-party organization. Emails will come from this organization, not from us ? once again, modelling \citet{kalla2016campaign}'s experiment. We could reach out to think tanks, policy labs, advocacy groups to partner with for this project. If we work with state and local policy makers, we will try to find a group with a large geographic and regional presence. It would be better to reach out to policy-makers in Idaho with a group with some presence if not in Idaho, at least in the northwest. 

\subsection{Federal or state level?} \label{sec: Level}

Conducting the experiment at the federal level would be substantially interesting (we are using recent initiatives happening at the federal level as motivations for this project). It might also be logistically easier to organise and attend meetings at the federal level. But we might end up conducting it at the State or more local levels, for multiple reasons. First, we might encounter power issues if we have multiple treatment arms and a fixed N of 535 (see \nameref{sec:Power}). Second, only two policy areas have existing, well-defined evidence standards and associated studies: education and labor policies. If the policy we end up choosing is mostly conducted at the state and local level, it might make substantially more sense to conduct the experiment at this level. Finally, there is a substantive interest as to whether state and local politics can help compensate for the shortcomings of the federal level, both in terms of quantity (gridlock) and quality (less polarized, more time to act). 

\section{Experimental analysis} \label{sec:analysis}

\subsection{Estimation of treatment effects} \label{sec:treatment_effects}



\section{Ethical considerations} \label{sec:Ethics}



\section{Power Analysis} \label{sec:Power}

We perform a power analysis in order to estimate the maximum number of treatment groups that may be advisable to include in the experiment given sample size and budgetary constraints. Preliminary power analyses are depicted below, and derive their assumptions regarding hypothetical response rates and treatment effect sizes from \citet{kalla2016campaign}.

The first power analysis assumes a sample size of 535 respondents (i.e. the number of representatives in the US Congress). In \citet{kalla2016campaign}, congressional offices granted meetings in response to requests roughly 50\% of the time. However, as the organizations requesting meetings were political donors (whether revealed or not), we believe that such a success rate may be unreasonably high, and therefore conduct our power analysis assuming a more conservative 30\% of offices will grant meetings.


\section{Conclusion} \label{sec:Conclusion}


\clearpage
\pagebreak
\bibliography{bibliography}

\pagebreak

\appendix
\setcounter{table}{0}
\setcounter{figure}{0}
\renewcommand\thetable{\Alph{section}.\arabic{table}}
\renewcommand\thefigure{\Alph{section}.\arabic{figure}}
\section{Appendix} \label{Appendix}

\subsection{Department of Education evidence tiers} \label{sec: DoE}


\end{document} 